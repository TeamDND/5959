from flask import request, jsonify
import os
from PIL import Image
# from transformers import pipeline
import base64
import io
from dotenv import load_dotenv
from openai import OpenAI

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
api_key = os.getenv('OPENAI_API_KEY')
client = None
if api_key:
    client = OpenAI(api_key=api_key)
    print("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
else:
    print("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ë¶„ì„ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# API í‚¤ í™•ì¸
if not os.getenv('OPENAI_API_KEY'):
    print("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    print("í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
else:
    print("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")

def call_ai_service(prompt):
    """AI ì„œë¹„ìŠ¤ í˜¸ì¶œ í•¨ìˆ˜"""
    try:
        if not client:
            return "AI ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ì½˜í…ì¸  ë¶„ì„ê°€ì…ë‹ˆë‹¤. ìš”ì²­ë°›ì€ ë‚´ìš©ì„ ì •í™•í•˜ê³  êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=4000,
            temperature=0.7
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        print(f"AI ì„œë¹„ìŠ¤ í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}")
        return f"AI ì„œë¹„ìŠ¤ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def extract_text_from_image(image_data):
    """ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        if not client:
            return "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        # base64 ë°ì´í„° ë¶€ë¶„ë§Œ ì¶”ì¶œ
        if ',' in image_data:
            image_data = image_data.split(',')[1]
        
        # OpenAI GPT Visionìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "ì´ ì´ë¯¸ì§€ì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•íˆ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ì´ë¯¸ì§€ì— ìˆëŠ” ëª¨ë“  ê¸€ì, ìˆ«ì, ê¸°í˜¸, í‘œ, ê·¸ë˜í”„ì˜ í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ì—¬ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”. í…ìŠ¤íŠ¸ê°€ ì—¬ëŸ¬ ì¤„ì´ë‚˜ ì—¬ëŸ¬ ì„¹ì…˜ì— ìˆë‹¤ë©´ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ì—¬ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ê¸¸ì´ ì œí•œ ì—†ì´ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ì´ë¯¸ì§€ì— í…ìŠ¤íŠ¸ê°€ ì „í˜€ ì—†ë‹¤ë©´ 'í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë‹µë³€í•´ì£¼ì„¸ìš”."
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_data}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=4000
        )
        
        extracted_text = response.choices[0].message.content
        
        # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸
        print(f"=== í…ìŠ¤íŠ¸ ì¶”ì¶œ ê²°ê³¼ ===")
        print(f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {extracted_text}")
        print(f"=======================")
        
        # í…ìŠ¤íŠ¸ê°€ ì—†ê±°ë‚˜ "í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ëŠ” ë©”ì‹œì§€ì¸ ê²½ìš°
        if not extracted_text.strip() or "í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤" in extracted_text:
            print("í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ - None ë°˜í™˜")
            return None  # Noneì„ ë°˜í™˜í•˜ì—¬ ì‹¤íŒ¨ë¥¼ ëª…í™•íˆ í‘œì‹œ
        
        print("í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ")
        return extracted_text
        
    except Exception as e:
        print(f"ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
        return None

def summarize_text_logic(text):
    """í…ìŠ¤íŠ¸ ìš”ì•½ ë¡œì§"""
    if len(text) < 50:
        return text
    
    # í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸° (ëª¨ë¸ ì œí•œ ê³ ë ¤)
    max_length = 1024
    if len(text) > max_length:
        text = text[:max_length]
    
    # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìš”ì•½ ë¡œì§
    text_length = len(text)
    if text_length < 200:
        # ì§§ì€ í…ìŠ¤íŠ¸ëŠ” ê·¸ëŒ€ë¡œ ë°˜í™˜
        result = text
    else:
        # ê¸´ í…ìŠ¤íŠ¸ëŠ” ì²« 200ì + "..." ë°˜í™˜
        result = text[:200] + "..."
    
    return result

def summarize_image_logic(image_data):
    """ì´ë¯¸ì§€ ìš”ì•½ ë¡œì§"""
    try:
        # OpenAI í´ë¼ì´ì–¸íŠ¸ í™•ì¸
        if not client:
            return {'error': 'OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ë¶„ì„ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}
        
        # base64 ë°ì´í„° ë¶€ë¶„ë§Œ ì¶”ì¶œ
        if ',' in image_data:
            image_data = image_data.split(',')[1]
        
        # OpenAI GPT Visionìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "ì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:\n\nğŸ“Š **ë‚´ìš© ë¶„ë¥˜**: [ë‹¤ìŒ ì¤‘ í•˜ë‚˜ ì„ íƒ]\n- ğŸ“š ê³µë¶€/í•™ìŠµ ë‚´ìš© (ìˆ˜ì—… ë…¸íŠ¸, êµì¬, ë¬¸ì œì§‘, ê°œë… ì •ë¦¬ ë“±)\n- ğŸ“° ë‰´ìŠ¤/ê¸°ì‚¬ ë‚´ìš© (ì‹ ë¬¸, ì¡ì§€, ì˜¨ë¼ì¸ ê¸°ì‚¬ ë“±)\n- ğŸ“„ ë¬¸ì„œ/ì„œë¥˜ (ê³µë¬¸ì„œ, ê³„ì•½ì„œ, ë³´ê³ ì„œ ë“±)\n- ğŸ’¼ ì—…ë¬´/íšŒì‚¬ ë‚´ìš© (íšŒì˜ë¡, ì—…ë¬´ ìë£Œ ë“±)\n- ğŸ  ê°œì¸/ì¼ìƒ ë‚´ìš© (ì¼ê¸°, ë©”ëª¨, ê°œì¸ ê¸°ë¡ ë“±)\n- â“ ê¸°íƒ€/ë¶„ë¥˜ ë¶ˆê°€\n\nğŸ” **ë¶„ë¥˜ ê·¼ê±°**: [ì™œ ì´ ë¶„ë¥˜ë¥¼ ì„ íƒí–ˆëŠ”ì§€ ì„¤ëª…]\n\nğŸ“‹ **ì£¼ìš” ë‚´ìš©**: [í•µì‹¬ ë‚´ìš© ìš”ì•½ - ì´ë¯¸ì§€ì— ìˆëŠ” ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ì—¬ ìƒì„¸í•˜ê²Œ ì„¤ëª…]\n\nğŸ“š **ê³µë¶€ ë‚´ìš© ì •ë¦¬** (ê³µë¶€/í•™ìŠµ ë‚´ìš©ìœ¼ë¡œ ë¶„ë¥˜ëœ ê²½ìš°ì—ë§Œ ë°˜ë“œì‹œ ì‘ì„±):\n- ğŸ¯ í•µì‹¬ ê°œë…: [ì´ë¯¸ì§€ì—ì„œ ë°œê²¬ëœ ì¤‘ìš”í•œ ê°œë…, ìš©ì–´, ì¸ë¬¼, ì‚¬ê±´ ë“±ì„ ë‚˜ì—´]\n- ğŸ“ ìš”ì•½ ë…¸íŠ¸: [ì´ë¯¸ì§€ì˜ ë‚´ìš©ì„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬]\n- â“ ì§ˆë¬¸/í™•ì¸ì‚¬í•­: [ì´ ë‚´ìš©ê³¼ ê´€ë ¨í•´ì„œ ë” ì•Œì•„ë³´ë©´ ì¢‹ì„ ì§ˆë¬¸ì´ë‚˜ í™•ì¸ì´ í•„ìš”í•œ ë¶€ë¶„]\n- ğŸ”— ê´€ë ¨ ì£¼ì œ: [ì´ ë‚´ìš©ê³¼ ì—°ê´€ëœ ë‹¤ë¥¸ í•™ìŠµ ì£¼ì œë‚˜ ë°°ê²½ ì§€ì‹]\n\nâš ï¸ ë§¤ìš° ì¤‘ìš”: ê³µë¶€/í•™ìŠµ ë‚´ìš©ìœ¼ë¡œ ë¶„ë¥˜í–ˆë‹¤ë©´ ë°˜ë“œì‹œ ìœ„ì˜ 4ê°€ì§€ í•­ëª©ì„ ëª¨ë‘ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. ë¹ˆ í•­ëª©ìœ¼ë¡œ ë‘ì§€ ë§ˆì„¸ìš”! ê° í•­ëª©ì— ì‹¤ì œ ë‚´ìš©ì„ ë°˜ë“œì‹œ í¬í•¨í•´ì£¼ì„¸ìš”!"
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_data}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=4000
        )
        extracted_text = response.choices[0].message.content
        
        # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸ ì¶”ê°€
        print("=== GPT Vision ì‘ë‹µ ===")
        print(extracted_text)
        print("======================")
        
        if not extracted_text.strip():
            return {'error': 'ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}
        
        # GPT Vision ë¶„ì„ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”í•˜ì—¬ ë°˜í™˜
        lines = extracted_text.split('\n')
        classification_info = ""
        main_content = ""
        study_notes = ""
        is_study_content = False
        in_study_notes = False
        in_main_content = False
        
        for line in lines:
            line_stripped = line.strip()
            
            if line.startswith('ğŸ“Š **ë‚´ìš© ë¶„ë¥˜**') or 'ğŸ“Š' in line and 'ë‚´ìš© ë¶„ë¥˜' in line:
                classification_info += line + '\n'
                # ê³µë¶€/í•™ìŠµ ë‚´ìš©ì¸ì§€ í™•ì¸
                if 'ğŸ“š ê³µë¶€/í•™ìŠµ ë‚´ìš©' in line or 'ê³µë¶€' in line or 'í•™ìŠµ' in line:
                    is_study_content = True
            elif line.startswith('ğŸ” **ë¶„ë¥˜ ê·¼ê±°**') or 'ğŸ”' in line and 'ë¶„ë¥˜ ê·¼ê±°' in line:
                classification_info += line + '\n'
            elif line.startswith('ğŸ“‹ **ì£¼ìš” ë‚´ìš©**') or 'ğŸ“‹' in line and 'ì£¼ìš” ë‚´ìš©' in line:
                # ì£¼ìš” ë‚´ìš© ì„¹ì…˜ ì‹œì‘
                in_main_content = True
                main_content_line = line.replace('ğŸ“‹ **ì£¼ìš” ë‚´ìš©**: ', '').replace('ğŸ“‹ **ì£¼ìš” ë‚´ìš©**:', '').replace('ğŸ“‹', '').replace('**ì£¼ìš” ë‚´ìš©**', '').replace(':', '').strip()
                if main_content_line:
                    main_content += main_content_line + ' '
            elif in_main_content and not line.startswith('ğŸ“š') and not line.startswith('ğŸ“Š') and not line.startswith('ğŸ”') and line_stripped:
                # ì£¼ìš” ë‚´ìš© ì„¹ì…˜ ë‚´ì˜ í…ìŠ¤íŠ¸
                main_content += line_stripped + ' '
            elif line.startswith('ğŸ“š **ê³µë¶€ ë‚´ìš© ì •ë¦¬**') or 'ğŸ“š' in line and 'ê³µë¶€ ë‚´ìš© ì •ë¦¬' in line:
                in_study_notes = True
                in_main_content = False
                study_notes += line + '\n'
                is_study_content = True  # ê³µë¶€ ë‚´ìš© ì •ë¦¬ê°€ ìˆìœ¼ë©´ í•™ìŠµ ë‚´ìš©ìœ¼ë¡œ íŒë‹¨
            elif in_study_notes and (line.startswith('- ğŸ¯') or line.startswith('- ğŸ“') or line.startswith('- â“') or line.startswith('- ğŸ”—') or line_stripped.startswith('-') or line_stripped):
                study_notes += line + '\n'
            elif in_study_notes and line_stripped == '':
                study_notes += line + '\n'
            elif in_study_notes and not line.startswith('ğŸ“Š') and not line.startswith('ğŸ”') and not line.startswith('ğŸ“‹'):
                # ê³µë¶€ ë‚´ìš© ì •ë¦¬ ì„¹ì…˜ ë‚´ì˜ ì¼ë°˜ í…ìŠ¤íŠ¸ë„ í¬í•¨
                study_notes += line + '\n'
        
        # main_contentê°€ ë¹„ì–´ìˆëŠ” ê²½ìš° ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©
        if not main_content.strip():
            # ê³µë¶€ ë‚´ìš© ì •ë¦¬ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ main_contentë¡œ ì‚¬ìš©
            if study_notes.strip():
                main_content = "ì´ë¯¸ì§€ì—ì„œ í•™ìŠµ ë‚´ìš©ì„ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤. ìƒì„¸ ë‚´ìš©ì€ ì•„ë˜ í•™ìŠµ ë…¸íŠ¸ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”."
                is_study_content = True
            else:
                # ê·¸ê²ƒë„ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•´ì„œ ì‚¬ìš©
                main_content = extracted_text[:300] + ('...' if len(extracted_text) > 300 else '')
        
        # ê²°ê³¼ êµ¬ì„±
        result = {
            'classification': classification_info.strip() if classification_info.strip() else 'ì´ë¯¸ì§€ í…ìŠ¤íŠ¸',
            'main_content': main_content.strip(),
            'is_study_content': is_study_content,
            'study_notes': study_notes.strip() if is_study_content else ""
        }
        
        print(f"=== íŒŒì‹± ê²°ê³¼ ===")
        print(f"classification: {result['classification']}")
        print(f"main_content: {result['main_content'][:100]}...")
        print(f"is_study_content: {result['is_study_content']}")
        print(f"study_notes length: {len(result['study_notes'])}")
        print("==================")
        
        return result
        
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return {'error': f'ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}

def generate_image_logic(content):
    """ì´ë¯¸ì§€ ìƒì„± ë¡œì§ - HTML/CSSë¡œ í•œê¸€ ë…¸íŠ¸ ìƒì„±"""
    try:
        # HTML í…œí”Œë¦¿ ìƒì„±
        html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <style>
        body {{
            font-family: 'Noto Sans KR', 'Malgun Gothic', sans-serif;
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
        }}
        .study-note {{
            background: white;
            border-radius: 15px;
            padding: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
            max-width: 800px;
            width: 100%;
        }}
        .title {{
            text-align: center;
            color: #333;
            font-size: 24px;
            font-weight: bold;
            margin-bottom: 30px;
            border-bottom: 3px solid #667eea;
            padding-bottom: 15px;
        }}
        .section {{
            margin-bottom: 25px;
            padding: 20px;
            border-radius: 10px;
            border-left: 5px solid;
        }}
        .section h3 {{
            margin: 0 0 15px 0;
            font-size: 18px;
            font-weight: bold;
        }}
        .section p {{
            margin: 5px 0;
            line-height: 1.6;
            color: #555;
        }}
        .concepts {{
            background: #f0f8ff;
            border-left-color: #4CAF50;
        }}
        .summary {{
            background: #fff8e1;
            border-left-color: #FF9800;
        }}
        .questions {{
            background: #f3e5f5;
            border-left-color: #9C27B0;
        }}
        .related {{
            background: #e8f5e8;
            border-left-color: #2196F3;
        }}
        .icon {{
            font-size: 20px;
            margin-right: 10px;
        }}
    </style>
</head>
<body>
    <div class="study-note">
        <div class="title">ğŸ“š í•™ìŠµ ë…¸íŠ¸</div>
        
        <div class="section concepts">
            <h3><span class="icon">ğŸ¯</span>í•µì‹¬ ê°œë…</h3>
            <p>{content.split('ğŸ¯ í•µì‹¬ ê°œë…:')[1].split('- ğŸ“ ìš”ì•½ ë…¸íŠ¸:')[0].replace('- ', 'â€¢ ').strip() if 'ğŸ¯ í•µì‹¬ ê°œë…:' in content else 'í•µì‹¬ ê°œë…ì´ ì—†ìŠµë‹ˆë‹¤.'}</p>
        </div>
        
        <div class="section summary">
            <h3><span class="icon">ğŸ“</span>ìš”ì•½ ë…¸íŠ¸</h3>
            <p>{content.split('- ğŸ“ ìš”ì•½ ë…¸íŠ¸:')[1].split('- â“ ì§ˆë¬¸/í™•ì¸ì‚¬í•­:')[0].replace('- ', 'â€¢ ').strip() if '- ğŸ“ ìš”ì•½ ë…¸íŠ¸:' in content else 'ìš”ì•½ ë…¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.'}</p>
        </div>
        
        <div class="section questions">
            <h3><span class="icon">â“</span>ì§ˆë¬¸/í™•ì¸ì‚¬í•­</h3>
            <p>{content.split('- â“ ì§ˆë¬¸/í™•ì¸ì‚¬í•­:')[1].split('- ğŸ”— ê´€ë ¨ ì£¼ì œ:')[0].replace('- ', 'â€¢ ').strip() if '- â“ ì§ˆë¬¸/í™•ì¸ì‚¬í•­:' in content else 'ì§ˆë¬¸/í™•ì¸ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.'}</p>
        </div>
        
        <div class="section related">
            <h3><span class="icon">ğŸ”—</span>ê´€ë ¨ ì£¼ì œ</h3>
            <p>{content.split('- ğŸ”— ê´€ë ¨ ì£¼ì œ:')[1].strip() if '- ğŸ”— ê´€ë ¨ ì£¼ì œ:' in content else 'ê´€ë ¨ ì£¼ì œê°€ ì—†ìŠµë‹ˆë‹¤.'}</p>
        </div>
    </div>
</body>
</html>
"""
        
        # HTMLì„ base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ë°ì´í„° URL ìƒì„±
        import base64
        html_bytes = html_content.encode('utf-8')
        html_base64 = base64.b64encode(html_bytes).decode('utf-8')
        
        # ë°ì´í„° URL ìƒì„±
        data_url = f"data:text/html;base64,{html_base64}"
        
        return {'image': data_url, 'type': 'html'}
        
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return {'error': f'ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}

def summarize_api():
    """ìš”ì•½ API ì—”ë“œí¬ì¸íŠ¸ ë¡œì§"""
    try:
        data = request.get_json()
        
        if 'text' in data and data['text']:
            # í…ìŠ¤íŠ¸ ìš”ì•½
            result = summarize_text_logic(data['text'])
            return jsonify({'summary': result, 'type': 'text'})
            
        elif 'image' in data and data['image']:
            # ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ ìš”ì•½
            result = summarize_image_logic(data['image'])
            return jsonify({'summary': result, 'type': 'image'})
            
        else:
            return jsonify({'error': 'í…ìŠ¤íŠ¸ ë˜ëŠ” ì´ë¯¸ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400
            
    except Exception as e:
        return jsonify({'error': str(e)}), 500

def generate_image_api():
    """ì´ë¯¸ì§€ ìƒì„± API ì—”ë“œí¬ì¸íŠ¸ ë¡œì§"""
    try:
        data = request.get_json()
        
        if not data or 'content' not in data:
            return jsonify({'error': 'ìƒì„±í•  ë‚´ìš©ì´ í•„ìš”í•©ë‹ˆë‹¤.'}), 400
        
        content = data['content']
        
        # AI ì„œë¹„ìŠ¤ë¡œ ì´ë¯¸ì§€ ìƒì„±
        result = generate_image_logic(content)
        
        if 'error' in result:
            return jsonify({'error': result['error']}), 400
        
        return jsonify({
            'image': result['image'],
            'message': 'ì´ë¯¸ì§€ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.'
        })
        
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return jsonify({'error': f'ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500

def analyze_content_api():
    """ì½˜í…ì¸  ë¶„ì„ API ì—”ë“œí¬ì¸íŠ¸ ë¡œì§"""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({'error': 'ìš”ì²­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'}), 400
        
        content_type = data.get('type', 'text')
        analysis_type = data.get('analysisType', 'general')
        
        if content_type == 'text' and 'text' in data and data['text']:
            # í…ìŠ¤íŠ¸ ë¶„ì„
            result = analyze_text_logic(data['text'], analysis_type)
            return jsonify({'summary': result, 'type': 'text'})
            
        elif content_type == 'image' and 'image' in data and data['image']:
            # ì´ë¯¸ì§€ ë¶„ì„
            result = analyze_image_logic(data['image'], analysis_type)
            return jsonify({'summary': result, 'type': 'image'})
            
        elif content_type == 'link' and 'link' in data and data['link']:
            # ë§í¬ ë¶„ì„
            result = analyze_link_logic(data['link'], analysis_type)
            return jsonify({'summary': result, 'type': 'link'})
            
        else:
            return jsonify({'error': 'ì˜¬ë°”ë¥¸ ì½˜í…ì¸  íƒ€ì…ê³¼ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400
            
    except Exception as e:
        print(f"ì½˜í…ì¸  ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return jsonify({'error': str(e)}), 500

def analyze_text_logic(text, analysis_type='general'):
    """í…ìŠ¤íŠ¸ ë¶„ì„ ë¡œì§"""
    try:
        # ë¶„ì„ ìœ í˜•ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
        if analysis_type == 'business':
            prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:

í…ìŠ¤íŠ¸: {text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSON ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "classification": "ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ë¥˜ (ì˜ˆ: ê¸°ì—… ì†Œê°œ, ì‹œì¥ ë¶„ì„, ì „ëµ ë“±)",
    "main_content": "ì£¼ìš” ë‚´ìš© ìš”ì•½",
    "key_points": ["í•µì‹¬ í¬ì¸íŠ¸ 1", "í•µì‹¬ í¬ì¸íŠ¸ 2", "í•µì‹¬ í¬ì¸íŠ¸ 3"],
    "sentiment": "ê°ì • ë¶„ì„ (ê¸ì •/ë¶€ì •/ì¤‘ë¦½)",
    "business_info": "ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ë ¨ ì •ë³´",
    "recommendations": ["ì¶”ì²œì‚¬í•­ 1", "ì¶”ì²œì‚¬í•­ 2"]
}}
"""
        elif analysis_type == 'study':
            prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í•™ìŠµ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:

í…ìŠ¤íŠ¸: {text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSON ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "classification": "í•™ìŠµ ë¶„ë¥˜ (ì˜ˆ: ê°œë… ì„¤ëª…, ì‹¤ìŠµ ê°€ì´ë“œ, ì´ë¡  ë“±)",
    "main_content": "ì£¼ìš” ë‚´ìš© ìš”ì•½",
    "key_points": ["í•µì‹¬ í¬ì¸íŠ¸ 1", "í•µì‹¬ í¬ì¸íŠ¸ 2", "í•µì‹¬ í¬ì¸íŠ¸ 3"],
    "sentiment": "ê°ì • ë¶„ì„ (ê¸ì •/ë¶€ì •/ì¤‘ë¦½)",
    "study_notes": "í•™ìŠµ ë…¸íŠ¸ í˜•íƒœë¡œ ì •ë¦¬",
    "recommendations": ["í•™ìŠµ ì¶”ì²œì‚¬í•­ 1", "í•™ìŠµ ì¶”ì²œì‚¬í•­ 2"]
}}
"""
        elif analysis_type == 'news':
            prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë‰´ìŠ¤ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:

í…ìŠ¤íŠ¸: {text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSON ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "classification": "ë‰´ìŠ¤ ë¶„ë¥˜ (ì˜ˆ: ê²½ì œ, ê¸°ìˆ , ì‚¬íšŒ, ì •ì¹˜ ë“±)",
    "main_content": "ì£¼ìš” ë‚´ìš© ìš”ì•½",
    "key_points": ["í•µì‹¬ í¬ì¸íŠ¸ 1", "í•µì‹¬ í¬ì¸íŠ¸ 2", "í•µì‹¬ í¬ì¸íŠ¸ 3"],
    "sentiment": "ê°ì • ë¶„ì„ (ê¸ì •/ë¶€ì •/ì¤‘ë¦½)",
    "impact_analysis": "ì˜í–¥ë„ ë¶„ì„",
    "recommendations": ["ê´€ë ¨ ì¶”ì²œì‚¬í•­ 1", "ê´€ë ¨ ì¶”ì²œì‚¬í•­ 2"]
}}
"""
        else:  # general
            prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ì¼ë°˜ì ì¸ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:

í…ìŠ¤íŠ¸: {text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSON ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "classification": "ë‚´ìš© ë¶„ë¥˜",
    "main_content": "ì£¼ìš” ë‚´ìš© ìš”ì•½",
    "key_points": ["í•µì‹¬ í¬ì¸íŠ¸ 1", "í•µì‹¬ í¬ì¸íŠ¸ 2", "í•µì‹¬ í¬ì¸íŠ¸ 3"],
    "sentiment": "ê°ì • ë¶„ì„ (ê¸ì •/ë¶€ì •/ì¤‘ë¦½)",
    "recommendations": ["ì¶”ì²œì‚¬í•­ 1", "ì¶”ì²œì‚¬í•­ 2"]
}}
"""
        
        # AI ì„œë¹„ìŠ¤ í˜¸ì¶œ
        response = call_ai_service(prompt)
        
        # JSON íŒŒì‹±
        try:
            import json
            result = json.loads(response)
            return result
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ êµ¬ì¡°ë¡œ ë°˜í™˜
            return {
                "classification": "ì¼ë°˜ í…ìŠ¤íŠ¸",
                "main_content": response,
                "key_points": [],
                "sentiment": "ì¤‘ë¦½",
                "recommendations": []
            }
            
    except Exception as e:
        print(f"í…ìŠ¤íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return {
            "classification": "ë¶„ì„ ì˜¤ë¥˜",
            "main_content": "í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "key_points": [],
            "sentiment": "ì¤‘ë¦½",
            "recommendations": []
        }

def analyze_image_logic(image_data, analysis_type='general'):
    """ì´ë¯¸ì§€ ë¶„ì„ ë¡œì§"""
    try:
        print("=== ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘ ===")
        
        # ë°”ë¡œ GPT Visionìœ¼ë¡œ ì „ì²´ ì´ë¯¸ì§€ ë¶„ì„ ì§„í–‰
        vision_result = summarize_image_logic(image_data)
        
        # ì—ëŸ¬ê°€ ìˆëŠ” ê²½ìš° ê¸°ë³¸ ê°’ ë°˜í™˜
        if 'error' in vision_result:
            return {
                "classification": "ì´ë¯¸ì§€ í…ìŠ¤íŠ¸",
                "main_content": "ì£„ì†¡í•˜ì§€ë§Œ ì´ ì´ë¯¸ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•´ ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ì˜ í•´ìƒë„ê°€ ì¶©ë¶„í•˜ì§€ ì•Šê±°ë‚˜ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì‘ì•„ì„œ ì¸ì‹í•˜ê¸° ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "is_study_content": False,
                "study_notes": "",
                "key_points": [],
                "sentiment": "ì¤‘ë¦½",
                "business_info": ""
            }
        
        # GPT Vision ê²°ê³¼ë¥¼ ë¶„ì„ í˜•ì‹ì— ë§ê²Œ ë³€í™˜
        return {
            "classification": "ì´ë¯¸ì§€ í…ìŠ¤íŠ¸",
            "main_content": vision_result.get('main_content', 'ì´ë¯¸ì§€ ë¶„ì„ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.'),
            "is_study_content": vision_result.get('is_study_content', False),
            "study_notes": vision_result.get('study_notes', ''),
            "key_points": [],
            "sentiment": "ì¤‘ë¦½",
            "business_info": ""
        }
            
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return {
            "classification": "ë¶„ì„ ì˜¤ë¥˜",
            "main_content": "ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "is_study_content": False,
            "study_notes": "",
            "key_points": [],
            "sentiment": "ì¤‘ë¦½",
            "business_info": ""
        }

def analyze_link_logic(url, analysis_type='general'):
    """ë§í¬ ë¶„ì„ ë¡œì§"""
    try:
        import requests
        from bs4 import BeautifulSoup
        
        # ì›¹í˜ì´ì§€ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ì œëª© ì¶”ì¶œ
        title = soup.find('title')
        title_text = title.get_text().strip() if title else "ì œëª© ì—†ìŒ"
        
        # ë©”íƒ€ ì„¤ëª… ì¶”ì¶œ
        meta_desc = soup.find('meta', attrs={'name': 'description'})
        description = meta_desc.get('content', '') if meta_desc else ""
        
        # ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ë²•)
        body = soup.find('body')
        if body:
            # ìŠ¤í¬ë¦½íŠ¸ì™€ ìŠ¤íƒ€ì¼ íƒœê·¸ ì œê±°
            for script in body(["script", "style"]):
                script.decompose()
            
            main_text = body.get_text()
            # í…ìŠ¤íŠ¸ ì •ë¦¬
            lines = (line.strip() for line in main_text.splitlines())
            chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
            main_text = ' '.join(chunk for chunk in chunks if chunk)
            
            # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
            if len(main_text) > 2000:
                main_text = main_text[:2000] + "..."
        else:
            main_text = "ë³¸ë¬¸ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ë¶„ì„ ìœ í˜•ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
        if analysis_type == 'business':
            prompt = f"""
ë‹¤ìŒ ì›¹í˜ì´ì§€ë¥¼ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:

URL: {url}
ì œëª©: {title_text}
ì„¤ëª…: {description}
ë³¸ë¬¸: {main_text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSON ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "title": "í˜ì´ì§€ ì œëª©",
    "description": "í˜ì´ì§€ ì„¤ëª…",
    "company_info": "ê¸°ì—… ì •ë³´",
    "key_insights": ["í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 1", "í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 2"],
    "market_analysis": "ì‹œì¥ ë¶„ì„",
    "recommendations": ["ì¶”ì²œì‚¬í•­ 1", "ì¶”ì²œì‚¬í•­ 2"]
}}
"""
        else:  # general
            prompt = f"""
ë‹¤ìŒ ì›¹í˜ì´ì§€ë¥¼ ì¼ë°˜ì ì¸ ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:

URL: {url}
ì œëª©: {title_text}
ì„¤ëª…: {description}
ë³¸ë¬¸: {main_text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ JSON ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
    "title": "í˜ì´ì§€ ì œëª©",
    "description": "í˜ì´ì§€ ì„¤ëª…",
    "company_info": "ê¸°ì—… ì •ë³´ (í•´ë‹¹í•˜ëŠ” ê²½ìš°)",
    "key_insights": ["í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 1", "í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 2"],
    "market_analysis": "ì‹œì¥ ë¶„ì„ (í•´ë‹¹í•˜ëŠ” ê²½ìš°)",
    "recommendations": ["ì¶”ì²œì‚¬í•­ 1", "ì¶”ì²œì‚¬í•­ 2"]
}}
"""
        
        # AI ì„œë¹„ìŠ¤ í˜¸ì¶œ
        response = call_ai_service(prompt)
        
        try:
            import json
            result = json.loads(response)
            return result
        except json.JSONDecodeError:
            return {
                "title": title_text,
                "description": description,
                "company_info": "",
                "key_insights": [],
                "market_analysis": "",
                "recommendations": []
            }
            
    except Exception as e:
        print(f"ë§í¬ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return {
            "title": "ë¶„ì„ ì˜¤ë¥˜",
            "description": "ë§í¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            "company_info": "",
            "key_insights": [],
            "market_analysis": "",
            "recommendations": []
        }